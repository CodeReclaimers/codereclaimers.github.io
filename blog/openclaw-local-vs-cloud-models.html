<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Local Models vs Cloud: A Tool-Calling Reality Check - CodeReclaimers</title>
    <meta name="description" content="Comparing local LLMs vs cloud models for AI tool-calling in OpenClaw. Testing Qwen, Gemma, Kimi, and Claude Haiku for complex tool schemas.">
    <link rel="canonical" href="https://codereclaimers.github.io/blog/openclaw-local-vs-cloud-models.html">
    <link rel="icon" type="image/svg+xml" href="/favicon.svg">

    <!-- Open Graph -->
    <meta property="og:title" content="Local Models vs Cloud: A Tool-Calling Reality Check">
    <meta property="og:description" content="Comparing local LLMs vs cloud models for AI tool-calling in OpenClaw. Testing Qwen, Gemma, Kimi, and Claude Haiku for complex tool schemas.">
    <meta property="og:url" content="https://codereclaimers.github.io/blog/openclaw-local-vs-cloud-models.html">
    <meta property="og:site_name" content="CodeReclaimers">
    <meta property="og:type" content="article">
    <meta property="article:published_time" content="2026-02-02">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Local Models vs Cloud: A Tool-Calling Reality Check">
    <meta name="twitter:description" content="Comparing local LLMs vs cloud models for AI tool-calling in OpenClaw. Testing Qwen, Gemma, Kimi, and Claude Haiku for complex tool schemas.">

    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;700&family=Source+Sans+Pro:wght@300;400;500&display=swap" rel="stylesheet">
    <link href="../css/style.css" rel="stylesheet">

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "headline": "Local Models vs Cloud: A Tool-Calling Reality Check",
        "datePublished": "2026-02-02",
        "author": {
            "@type": "Organization",
            "name": "CodeReclaimers, LLC",
            "url": "https://codereclaimers.github.io"
        },
        "publisher": {
            "@type": "Organization",
            "name": "CodeReclaimers, LLC",
            "url": "https://codereclaimers.github.io"
        },
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://codereclaimers.github.io/blog/openclaw-local-vs-cloud-models.html"
        }
    }
    </script>
</head>
<body>
    <div class="site-header">
        <p class="site-title"><a href="/">CodeReclaimers, LLC</a></p>
    </div>

    <div class="content">
        <a href="/" class="back-link">&larr; Back to CodeReclaimers</a>

        <h1>Local Models vs Cloud: A Tool-Calling Reality Check</h1>
        <p class="date">February 2, 2026</p>

        <p>After getting OpenClaw running in a VM (see
        <a href="/blog/openclaw-vm-setup.html">Part 1</a>), I set out to use local
        LLMs via Ollama. What followed was an educational journey through the current
        limitations of local model tool-calling.</p>

        <h2>The Memory Search API Key Problem</h2>

        <p>The first issue: OpenClaw's <code>memory_search</code> tool requires embeddings,
        which by default need an OpenAI API key. I tried several approaches:</p>

        <h3>Option 1: Disable the memory plugin entirely</h3>

<pre><code>{
  "plugins": {
    "slots": {
      "memory": "none"
    }
  }
}</code></pre>

        <h3>Option 2: Use local embeddings</h3>

<pre><code>{
  "agents": {
    "defaults": {
      "memorySearch": {
        "provider": "local"
      }
    }
  }
}</code></pre>

        <p>I also tried configuring Ollama for embeddings, but the <code>memorySearch.provider</code>
        only accepts <code>"openai"</code> or <code>"local"</code>, not custom endpoints.</p>

        <h2>Model Tool-Calling Issues</h2>

        <p>With memory sorted, I tested multiple local models. All had issues with OpenClaw's
        complex tool schemas:</p>

        <table>
            <tr><th>Model</th><th>Result</th></tr>
            <tr><td><code>qwen2.5:32b</code></td><td>Called tools but with wrong parameters</td></tr>
            <tr><td><code>qwen3:30b-a3b</code></td><td>Reasoning model, tool format issues</td></tr>
            <tr><td><code>gemma3:27b-it-qat</code></td><td><strong>"does not support tools"</strong> error</td></tr>
            <tr><td><code>qwen2.5-coder:14b</code></td><td>Still had parameter issues</td></tr>
        </table>

        <p>The Gemma3 error was explicit:</p>

<pre><code>"errorMessage": "400 registry.ollama.ai/library/gemma3:27b-it-qat does not support tools"</code></pre>

        <p>The Qwen models had a subtler problem: they would recognize they needed to call
        a tool but send empty <code>{}</code> for complex nested parameters like cron job
        specifications. They'd get stuck in loops trying repeatedly with the same empty parameters.</p>

        <h2>Trying Cloud Models</h2>

        <p>I switched to OpenCode Zen as the primary provider:</p>

<pre><code>{
  "agents": {
    "defaults": {
      "model": {
        "primary": "opencode/kimi-k2.5",
        "fallbacks": ["ollama/qwen2.5-coder:14b"]
      }
    }
  }
}</code></pre>

        <h3>Rate Limiting with Free Tier</h3>

        <p>The free tier (<code>opencode/kimi-k2.5-free</code>) hit rate limits quickly:</p>

<pre><code>"errorMessage": "429 Request didn't generate first token before the given deadline, the service is overloaded"</code></pre>

        <p>Switching to the paid tier <code>opencode/kimi-k2.5</code> resolved this.</p>

        <h3>Kimi Still Struggled with Complex Tools</h3>

        <p>Even the cloud Kimi model had issues with complex tool schemas. When trying to
        add cron jobs, it repeatedly sent empty job objects despite its "thinking" showing
        it knew what parameters were needed.</p>

        <h2>The Solution: Claude Haiku</h2>

        <p>I finally switched to <code>opencode/claude-haiku-4-5</code> for reliable tool calling:</p>

<pre><code>{
  "agents": {
    "defaults": {
      "model": {
        "primary": "opencode/claude-haiku-4-5",
        "fallbacks": ["ollama/qwen2.5-coder:14b"]
      }
    }
  }
}</code></pre>

        <p>This worked reliably. The local Ollama model serves as a fallback for simpler
        tasks or when the cloud is unavailable.</p>

        <h2>Lessons Learned</h2>

        <ol>
            <li><strong>Local model tool-calling is immature.</strong> Even capable models
            like Qwen 2.5 32B struggle with complex nested tool schemas. Simple chat works;
            complex agentic workflows don't.</li>

            <li><strong>Ollama tool support varies by model.</strong> Some models (Gemma3)
            explicitly don't support tools. Check before assuming.</li>

            <li><strong>Memory search requires embeddings.</strong> Either disable it, use
            local embeddings, or accept the OpenAI API key requirement.</li>

            <li><strong>Claude models handle tools reliably.</strong> When tool-calling
            reliability matters, Claude (even Haiku) is a safer choice than experimental
            alternatives.</li>
        </ol>

        <h2>Final Model Configuration</h2>

        <table>
            <tr><th>Component</th><th>Value</th></tr>
            <tr><td>Primary Model</td><td><code>opencode/claude-haiku-4-5</code></td></tr>
            <tr><td>Fallback Model</td><td><code>ollama/qwen2.5-coder:14b</code></td></tr>
            <tr><td>Memory Search</td><td>Disabled</td></tr>
        </table>

        <div class="series-nav">
            <strong>OpenClaw VM Setup Series</strong>
            Part 1: <a href="/blog/openclaw-vm-setup.html">Setting Up OpenClaw in an Isolated VM</a><br>
            Part 2: Local Models vs Cloud: A Tool-Calling Reality Check (this post)<br>
            Part 3: <a href="/blog/openclaw-operations.html">Running OpenClaw: Security, Automation & Maintenance</a>
        </div>

        <footer>
            <p>CodeReclaimers is a veteran-owned business located in Ramseur, NC USA.</p>
        </footer>
    </div>
</body>
</html>
